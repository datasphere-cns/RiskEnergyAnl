library('cluster')
************
K-MEANS ALGORITHM
************
#Read data
setwd("C:/Users/Nelson/Desktop/DataSphere/EventoLanzamiento/BaseSegmentacion")
ds<-read.table("BaseEstandar.csv",dec=".",sep=",",header=TRUE,colClasses=c("numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric"))
#Select the number of clusters based on:	a) The sum of squared error (SSE)
	   kmax <- 10
	   res <- rep(0,kmax)
	   for(i in 1:kmax){
	      res[i] <- kmeans(ds,i,nstart=30)$tot.withinss
	   }
plot(1:kmax,res,type="b",pch=19,frame=FALSE,xlab="Number of clusters K",ylab="Total within-clusters sum of squares")	   

#b) The percentage of variance explained
kmax <- 10
res <- rep(0,kmax)	   
for(i in 1:kmax){
	      kmmtemp <- kmeans(ds,i,nstart=30)
	      res[i] <- kmmtemp$betweenss/kmmtemp$totss
	   }
plot(1:kmax,res,type="b",pch=19,frame=FALSE,xlab="Number of clusters K",ylab="Total variance explained")

#c) The Silhouette coefficient
kmax <- 10
res <- rep(0,kmax)
for(i in 2:kmax){
	      kmmtemp <- kmeans(ds,i,nstart=30)
	      resv <- silhouette(kmmtemp$cluster,dist(ds))
	      res[i] <- mean(resv[,3])
	   }
plot(1:kmax,res,type="b",pch=19,frame=FALSE,xlab="Number of clusters K",ylab="Silhouette coeficient")	   

	   
######################################################################################################################
#Build the model. To account for different initial seed selection we ask to try 30 different random starting assignments (nstart=30) and select the one with the lowest SSE.
kmm <- kmeans(ds,5,iter.max=100,nstart=30)
#Combine dataset and clusters. Write the new dataset to file.
dsnew <- cbind(ds,kmm$cluster)
write.table(dsnew,file="clusters_kmeans.csv",row.names=FALSE)



#####################PCA

ds<-read.table("C:/Users/Nelson/Desktop/DataSphere/EventoLanzamiento/BaseSegmentacion/SoloNumericAtt.csv",dec=".",sep=",",header=TRUE,colClasses=c("numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric"))
x11()
plot(ds)
x11()
boxplot(ds, col='gold')
### Principal components analysis on the standardized data
ds.sd <- scale(ds)
ds.sd <- data.frame(ds.sd)
x11()
boxplot(ds.sd, col='gold')

ds.sd<-ds.sd[complete.cases(ds.sd),]
pc.ds <- princomp(ds.sd, scores=T)

# loadings 
load.rec <- pc.ds$loadings
load.rec

# graphical representation of the loadings of the principal components
x11()
par(mar = c(1,4,0,2), mfrow = c(4,1))
for(i in 1:4) barplot(load.rec[,i], ylim = c(-1, 1))

x11()
layout(matrix(c(2,3,1,3),2,byrow=T))
barplot(pc.ds$sdev^2, las=2, main='Principal components', ylim=c(0,7), ylab='Variances') 
abline(h=1, col='blue')

barplot(sapply(ds.sd,sd)^2, las=2, main='Original variables', ylim=c(0,7), ylab='Variances') 
plot(cumsum(pc.ds$sd^2)/sum(pc.ds$sd^2), type='b', axes=F, xlab='number of components', ylab='contribution to the total variace', ylim=c(0,1)) 
x11()
scores.ds <- pc.ds$scores
scores.ds <- data.frame(scores.ds)
plot(scores.ds[,1],scores.ds[,2],type="n",xlab="pc1",ylab="pc2", asp=1)
text(scores.ds[,1],scores.ds[,2],dimnames(ds)[[1]],cex=1)
# biplot
x11()
biplot(pc.ds, scale=0, cex=.7)

